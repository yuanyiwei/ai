---
documentclass: ctexart # for linux title: 人工智能实验二 author: PB18000221 袁一玮

# date: 5 月 11 日

CJKmainfont: "Microsoft YaHei" # for win
# CJKmainfont: "KaiTi" # for win
---

## 传统机器学习

### 最小二乘分类

参考下面的做法，可以使用梯度下降法求解

![1.1](fig/1.1.png)

![1.2](fig/1.2.png)

得到迭代式：

输出结果入下

![1.out](fig/1.out.png)

### 朴素贝叶斯

对 feature[0] 使用离散计算频率（拉普拉斯平滑处理）的方法，对 feature[1..7] 采用使用高斯分布（正态分布）拟合

1：统计相关信息阶段，遍历整个训练数据集（train_data)，统计各个categories的数量，统计feature[0]取值为1，2，3时各个categories的数量，统计feature[1..7]
在不同categories分类的子集下的数据集（subset_array）； 2：拟合阶段，Pc和对feature[0]的条件概率都还是按照 来进行计算。其中Pxc[(i,0,j)]表示在第i个categories（i =
1，2，3）中，feature[0] = j（j = 1，2，3）出现的概率；Pc[c]表示categories c 出现的概率。 针对连续性特征feature[1..7]
，我们统计各个subset_array的均值（mean）和标准差（s_d); 然后把这一组参数特征（唯一地决定了高斯分布的表达式）赋值给Pxc[(i,j)]表示第i个categories中第j（j =
1，2，3...7）个属性的分布参数情况。 然后，训练阶段（fit）完成。

![2.out](fig/2.out.png)

### 支持向量机

## 深度学习

### 手写感知机模型

### MLP-Mixer
